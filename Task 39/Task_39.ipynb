{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74p2jmhdll-6"
      },
      "source": [
        "<h1 align = center>Implemention Of RNN Using TensorFlow/Keras </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XobnH672ll-9"
      },
      "source": [
        "#### What  is RNN ?\n",
        "\n",
        "A Recurrent Neural Network (RNN) is a type of artificial neural network that uses sequential data, such as text, audio, and video. RNNs have been widely used in various fields, including natural language processing, speech recognition, and image and video recognition.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxaaiVTQll-9"
      },
      "source": [
        "<h2 align = center> Importing Necessary Libraries </h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "wUD-sPTrll--"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import tensorflow\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjhdIh1Ull-_"
      },
      "source": [
        "<h2 align =center> Importing Data </h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "UXyyVckIll-_"
      },
      "outputs": [],
      "source": [
        "text = [\"Maybe life is random, but I doubt it.\",\"It's takin' whatever comes your way, the good AND the bad, that give life flavor. It's all the stuff rolled together that makes life worth livin'.\",\"The most exciting phrase to hear in science, the one that heralds new discoveries, is not 'Eureka!' (I found it!) but 'That's funny ...'\",\"My guess is that well over 80 percent of the human race goes without having a single original thought.\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRpuHdPLll_A"
      },
      "source": [
        "<h2 align = center> Data Preprocessing </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LfJ-la_ll_A"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "2UWOpEc-ll_A"
      },
      "outputs": [],
      "source": [
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAy8QKaUll_A"
      },
      "source": [
        "### Creating Input Sequence\n",
        "\n",
        "#### What is Input Sequence in RNN ?\n",
        "\n",
        "A sequence of data points that are fed into a neural network, such as a recurrent neural network (RNN), is called an input sequence. In RNN, the output of a layer at time step t is used as the input for the layer at time step t+1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdlAXd6sll_B",
        "outputId": "1105e118-c60c-4346-cfe7-aff045c2b817"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 3],\n",
              " [10, 3, 4],\n",
              " [10, 3, 4, 11],\n",
              " [10, 3, 4, 11, 5],\n",
              " [10, 3, 4, 11, 5, 6],\n",
              " [10, 3, 4, 11, 5, 6, 12],\n",
              " [10, 3, 4, 11, 5, 6, 12, 7],\n",
              " [8, 13],\n",
              " [8, 13, 14],\n",
              " [8, 13, 14, 15],\n",
              " [8, 13, 14, 15, 16],\n",
              " [8, 13, 14, 15, 16, 17],\n",
              " [8, 13, 14, 15, 16, 17, 1],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19, 1],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19, 1, 20],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19, 1, 20, 2],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19, 1, 20, 2, 21],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19, 1, 20, 2, 21, 3],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19, 1, 20, 2, 21, 3, 22],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19, 1, 20, 2, 21, 3, 22, 8],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19, 1, 20, 2, 21, 3, 22, 8, 23],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19, 1, 20, 2, 21, 3, 22, 8, 23, 1],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19, 1, 20, 2, 21, 3, 22, 8, 23, 1, 24],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19, 1, 20, 2, 21, 3, 22, 8, 23, 1, 24, 25],\n",
              " [8, 13, 14, 15, 16, 17, 1, 18, 19, 1, 20, 2, 21, 3, 22, 8, 23, 1, 24, 25, 26],\n",
              " [8,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  1,\n",
              "  18,\n",
              "  19,\n",
              "  1,\n",
              "  20,\n",
              "  2,\n",
              "  21,\n",
              "  3,\n",
              "  22,\n",
              "  8,\n",
              "  23,\n",
              "  1,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  2],\n",
              " [8,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  1,\n",
              "  18,\n",
              "  19,\n",
              "  1,\n",
              "  20,\n",
              "  2,\n",
              "  21,\n",
              "  3,\n",
              "  22,\n",
              "  8,\n",
              "  23,\n",
              "  1,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  2,\n",
              "  27],\n",
              " [8,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  1,\n",
              "  18,\n",
              "  19,\n",
              "  1,\n",
              "  20,\n",
              "  2,\n",
              "  21,\n",
              "  3,\n",
              "  22,\n",
              "  8,\n",
              "  23,\n",
              "  1,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  2,\n",
              "  27,\n",
              "  3],\n",
              " [8,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  1,\n",
              "  18,\n",
              "  19,\n",
              "  1,\n",
              "  20,\n",
              "  2,\n",
              "  21,\n",
              "  3,\n",
              "  22,\n",
              "  8,\n",
              "  23,\n",
              "  1,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  2,\n",
              "  27,\n",
              "  3,\n",
              "  28],\n",
              " [8,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  1,\n",
              "  18,\n",
              "  19,\n",
              "  1,\n",
              "  20,\n",
              "  2,\n",
              "  21,\n",
              "  3,\n",
              "  22,\n",
              "  8,\n",
              "  23,\n",
              "  1,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  2,\n",
              "  27,\n",
              "  3,\n",
              "  28,\n",
              "  29],\n",
              " [1, 30],\n",
              " [1, 30, 31],\n",
              " [1, 30, 31, 32],\n",
              " [1, 30, 31, 32, 33],\n",
              " [1, 30, 31, 32, 33, 34],\n",
              " [1, 30, 31, 32, 33, 34, 35],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1, 37],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1, 37, 2],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1, 37, 2, 38],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1, 37, 2, 38, 39],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1, 37, 2, 38, 39, 40],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1, 37, 2, 38, 39, 40, 4],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1, 37, 2, 38, 39, 40, 4, 41],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1, 37, 2, 38, 39, 40, 4, 41, 42],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1, 37, 2, 38, 39, 40, 4, 41, 42, 9],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1, 37, 2, 38, 39, 40, 4, 41, 42, 9, 6],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1, 37, 2, 38, 39, 40, 4, 41, 42, 9, 6, 43],\n",
              " [1, 30, 31, 32, 33, 34, 35, 36, 1, 37, 2, 38, 39, 40, 4, 41, 42, 9, 6, 43, 7],\n",
              " [1,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  36,\n",
              "  1,\n",
              "  37,\n",
              "  2,\n",
              "  38,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  41,\n",
              "  42,\n",
              "  9,\n",
              "  6,\n",
              "  43,\n",
              "  7,\n",
              "  5],\n",
              " [1,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  36,\n",
              "  1,\n",
              "  37,\n",
              "  2,\n",
              "  38,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  41,\n",
              "  42,\n",
              "  9,\n",
              "  6,\n",
              "  43,\n",
              "  7,\n",
              "  5,\n",
              "  44],\n",
              " [1,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  36,\n",
              "  1,\n",
              "  37,\n",
              "  2,\n",
              "  38,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  41,\n",
              "  42,\n",
              "  9,\n",
              "  6,\n",
              "  43,\n",
              "  7,\n",
              "  5,\n",
              "  44,\n",
              "  45],\n",
              " [1,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  36,\n",
              "  1,\n",
              "  37,\n",
              "  2,\n",
              "  38,\n",
              "  39,\n",
              "  40,\n",
              "  4,\n",
              "  41,\n",
              "  42,\n",
              "  9,\n",
              "  6,\n",
              "  43,\n",
              "  7,\n",
              "  5,\n",
              "  44,\n",
              "  45,\n",
              "  9],\n",
              " [46, 47],\n",
              " [46, 47, 4],\n",
              " [46, 47, 4, 2],\n",
              " [46, 47, 4, 2, 48],\n",
              " [46, 47, 4, 2, 48, 49],\n",
              " [46, 47, 4, 2, 48, 49, 50],\n",
              " [46, 47, 4, 2, 48, 49, 50, 51],\n",
              " [46, 47, 4, 2, 48, 49, 50, 51, 52],\n",
              " [46, 47, 4, 2, 48, 49, 50, 51, 52, 1],\n",
              " [46, 47, 4, 2, 48, 49, 50, 51, 52, 1, 53],\n",
              " [46, 47, 4, 2, 48, 49, 50, 51, 52, 1, 53, 54],\n",
              " [46, 47, 4, 2, 48, 49, 50, 51, 52, 1, 53, 54, 55],\n",
              " [46, 47, 4, 2, 48, 49, 50, 51, 52, 1, 53, 54, 55, 56],\n",
              " [46, 47, 4, 2, 48, 49, 50, 51, 52, 1, 53, 54, 55, 56, 57],\n",
              " [46, 47, 4, 2, 48, 49, 50, 51, 52, 1, 53, 54, 55, 56, 57, 58],\n",
              " [46, 47, 4, 2, 48, 49, 50, 51, 52, 1, 53, 54, 55, 56, 57, 58, 59],\n",
              " [46, 47, 4, 2, 48, 49, 50, 51, 52, 1, 53, 54, 55, 56, 57, 58, 59, 60],\n",
              " [46, 47, 4, 2, 48, 49, 50, 51, 52, 1, 53, 54, 55, 56, 57, 58, 59, 60, 61]]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "\n",
        "sequences = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "# Generate input sequences and corresponding labels\n",
        "input_seq = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, len(seq)):\n",
        "        n_gram_sequence = seq[:i+1]\n",
        "        input_seq.append(n_gram_sequence)\n",
        "\n",
        "input_seq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dmwYhXmll_B"
      },
      "source": [
        "### Padding Sequence\n",
        "\n",
        "#### Why Padding is important in Sequence ?\n",
        "\n",
        "Padding is necessary in sequence data to make all sequences of the same length. This is because RNNs require all sequences to have the same length, and if a sequence is shorter than the maximum sequence length, padding is added to make it longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYFvX_Utll_B",
        "outputId": "558a4a4d-0e88-4cbf-92f9-a39925390ab2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0, 10,  3], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "max_seq_len = max([len(x) for x in input_seq])\n",
        "\n",
        "input_seq = np.array(pad_sequences(input_seq,maxlen=max_seq_len , padding='pre'))\n",
        "\n",
        "input_seq[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yH5Gk_Oll_C"
      },
      "source": [
        "### Splitting Data into input and output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpM_g2kQll_C"
      },
      "source": [
        "We splits sequences into input (X) with all tokens except the last one and output (y) with only the last token, to train a model to predict the next token based on the preceding ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "lK8h1Begll_C"
      },
      "outputs": [],
      "source": [
        "X = input_seq[:,:-1]\n",
        "y = input_seq[:,-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAoonCx3ll_C"
      },
      "source": [
        "### Converting y to one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ap_ZUVemll_C"
      },
      "outputs": [],
      "source": [
        "# Convert output labels to categorical format\n",
        "num_classes = len(tokenizer.word_index) + 1\n",
        "y = tensorflow.keras.utils.to_categorical(y, num_classes=num_classes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mETL47YAll_D"
      },
      "source": [
        "### Define RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "sIBSP0Atll_D"
      },
      "outputs": [],
      "source": [
        "model = tensorflow.keras.models.Sequential([\n",
        "    keras.layers.Embedding(input_dim=max_seq_len, output_dim=100),\n",
        "    keras.layers.SimpleRNN(units=300, activation='relu', return_sequences=True),\n",
        "    keras.layers.SimpleRNN(units=100, activation='relu'),\n",
        "\n",
        "\n",
        "    keras.layers.Dense(units=num_classes, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S62GB2C9ll_D"
      },
      "source": [
        "### Model Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "weBAvfBEll_E",
        "outputId": "9783da64-2b0f-4699-b572-dc076c2e0b84"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_4 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_5 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.compile(optimizer='adamW', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c0dNeHdll_E"
      },
      "source": [
        "### Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDz9iN4tll_E",
        "outputId": "8c00c4b0-b9b3-48a7-96e8-ee894b542ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 436ms/step - accuracy: 0.0068 - loss: 4.1360\n",
            "Epoch 2/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0427 - loss: 4.1034     \n",
            "Epoch 3/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0679 - loss: 4.0785\n",
            "Epoch 4/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0466 - loss: 4.0488\n",
            "Epoch 5/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0768 - loss: 3.9873 \n",
            "Epoch 6/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0903 - loss: 3.9242\n",
            "Epoch 7/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1194 - loss: 3.8457\n",
            "Epoch 8/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0864 - loss: 3.6774 \n",
            "Epoch 9/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1126 - loss: 3.5180\n",
            "Epoch 10/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2427 - loss: 3.2881 \n",
            "Epoch 11/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1980 - loss: 3.2303\n",
            "Epoch 12/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3874 - loss: 3.1406 \n",
            "Epoch 13/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3017 - loss: 2.9453\n",
            "Epoch 14/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4115 - loss: 2.3364 \n",
            "Epoch 15/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4680 - loss: 2.0377\n",
            "Epoch 16/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6759 - loss: 1.6348 \n",
            "Epoch 17/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6603 - loss: 1.4884 \n",
            "Epoch 18/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6048 - loss: 1.3497\n",
            "Epoch 19/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7544 - loss: 1.0453\n",
            "Epoch 20/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8234 - loss: 0.7620 \n",
            "Epoch 21/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8205 - loss: 0.6281\n",
            "Epoch 22/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8699 - loss: 0.6099 \n",
            "Epoch 23/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8124 - loss: 0.7210\n",
            "Epoch 24/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9048 - loss: 0.5748\n",
            "Epoch 25/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9030 - loss: 0.3877\n",
            "Epoch 26/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9019 - loss: 0.3296\n",
            "Epoch 27/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9573 - loss: 0.2511\n",
            "Epoch 28/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9563 - loss: 0.2467\n",
            "Epoch 29/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9350 - loss: 0.1949\n",
            "Epoch 30/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9350 - loss: 0.2228\n",
            "Epoch 31/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9932 - loss: 0.1650\n",
            "Epoch 32/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9456 - loss: 0.2059\n",
            "Epoch 33/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9641 - loss: 0.1552\n",
            "Epoch 34/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9311 - loss: 0.2949 \n",
            "Epoch 35/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9243 - loss: 0.5263\n",
            "Epoch 36/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9602 - loss: 0.3214\n",
            "Epoch 37/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8856 - loss: 0.4559\n",
            "Epoch 38/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9389 - loss: 0.2910\n",
            "Epoch 39/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9272 - loss: 0.2468\n",
            "Epoch 40/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9378 - loss: 0.2007\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X, y, epochs=40, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA26WHYbll_E"
      },
      "source": [
        "### Making A Prediction From The Passage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqw5Drqoll_E",
        "outputId": "902c2a86-ab7c-4ea9-f20c-551be4fb8bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "Next 6 Words After 'My guess is that well over 80 percent of the human race goes' are 'without having a single original thought'\n"
          ]
        }
      ],
      "source": [
        "number_of_words = 6\n",
        "\n",
        "\n",
        "prediction = \"My guess is that well over 80 percent of the human race goes\"\n",
        "seq = tokenizer.texts_to_sequences([prediction])[0]\n",
        "predicted_words = []\n",
        "for i in range(number_of_words):\n",
        "    paded_seq = pad_sequences([seq] , maxlen=max_seq_len-1 , padding= 'pre')\n",
        "    predicted = model.predict(paded_seq)\n",
        "    predicted_word_index = np.argmax(predicted)\n",
        "    predicted_word = tokenizer.index_word.get(predicted_word_index,'Unknown')\n",
        "\n",
        "    predicted_words.append(predicted_word)\n",
        "\n",
        "    seq.append(predicted_word_index)\n",
        "\n",
        "predicted_sentence = ' '.join(predicted_words)\n",
        "\n",
        "print(f\"Next {number_of_words} Words After '{prediction}' are '{predicted_sentence}'\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}