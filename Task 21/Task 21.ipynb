{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1 align = 'center'><font color = \"#967BB6\">Linear algebra and calculus in NumPy</font></h1>  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1 align = center> Importing Necessary Libraries </h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1 align = center><font color = #5865F2 >Linear Algebra Tasks</font></h1>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1 align = center><font color =#D462FF > 1. Matrix Creation and Manipulation</font></h1>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 align = center><font color =#CC338B >Create various types of matrices (zero matrix, identity matrix, random matrix).</font></h2>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 align = center><font color = '#F62217'> Zero Matrix</font></h2>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Zero Matrix\n",
    "\n",
    "A zero matrix is a matrix in which all the elements are zero. It is a special case of a square matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a zero matrix of size 3x3\n",
    "zeroMatrix = np.zeros(shape=(3,3), dtype='int32')\n",
    "zeroMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 align = center><font color = '#FF7900'> Identity Matrix</font></h2>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Identity Matrix ?\n",
    "\n",
    "An identity matrix is a square matrix in which all the elements on the principal diagonal are ones (1s) and all other elements are zeros. It is also known as a unit matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making identity matrix of size 3x3\n",
    "\n",
    "identityMatrix = np.eye(3, dtype='int32')\n",
    "identityMatrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 align = center><font color = '#2672FF'> Random Matrix</font></h2>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Random Matrix ?\n",
    "\n",
    "A random matrix is a matrix in which the elements are randomly generated numbers. It is often used in various applications, such as simulations, machine learning, and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  7, 11, 12,  4],\n",
       "       [22, 13,  2,  6, 20],\n",
       "       [13, 21,  2, 17,  7],\n",
       "       [ 6,  7,  1, 21, 23],\n",
       "       [20, 10, 12, 16, 24]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a random matrix of size 5x5\n",
    "\n",
    "randomMatrix = np.random.randint(1, 25, size=(5,5), dtype='int32')\n",
    "randomMatrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 align = center><font color =#CC338B >Perform basic matrix operations (addition, subtraction, multiplication).\n",
    "</font></h2>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<h2 align = center><font color = '#6AFB92'>Addition</font></h2>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix 1\n",
      "\n",
      "[[87 65 27 69 40]\n",
      " [ 8 99 52 56  5]\n",
      " [99 21 22 62 69]\n",
      " [93 67 44 93 72]\n",
      " [35 41 81  9 67]]\n",
      "\n",
      "Matrix 2\n",
      "\n",
      "[[46 51 20 31 80]\n",
      " [91 80 80 88  1]\n",
      " [62 43 27 17 22]\n",
      " [97  9 13 71 62]\n",
      " [63 37 45 22 70]]\n",
      "\n",
      "Resultant Matrix\n",
      "\n",
      "[[133 116  47 100 120]\n",
      " [ 99 179 132 144   6]\n",
      " [161  64  49  79  91]\n",
      " [190  76  57 164 134]\n",
      " [ 98  78 126  31 137]]\n"
     ]
    }
   ],
   "source": [
    "# Making 2 Random 5x5 Matrix\n",
    "\n",
    "mat1 = np.random.randint(1,100 , size=(5,5),dtype='int16')\n",
    "mat2 = np.random.randint(1,100 , size=(5,5),dtype='int16')\n",
    "\n",
    "# Showing Mat1 and Mat2\n",
    "\n",
    "print(f\"\\nMatrix 1\\n\")\n",
    "print(mat1)\n",
    "\n",
    "print(f\"\\nMatrix 2\\n\")\n",
    "print(mat2)\n",
    "\n",
    "# Adding the matrices\n",
    "\n",
    "mat3 = mat1+mat2\n",
    "\n",
    "print(f\"\\nResultant Matrix\\n\")\n",
    "print(mat3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 align = center><font color = '#FF7900'>Subtraction</font></h2>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix 1\n",
      "\n",
      "[[94  6 19 64  7]\n",
      " [37 97  2 55 84]\n",
      " [16 77 71 81 28]\n",
      " [11 15  8 77 35]\n",
      " [72 84 25 63 82]]\n",
      "\n",
      "Matrix 2\n",
      "\n",
      "[[93 51 70 22 96]\n",
      " [84 60 99  7 58]\n",
      " [10 94 94 52 47]\n",
      " [28 78  2 12 47]\n",
      " [73 58 38 27 59]]\n",
      "\n",
      "Resultant Matrix\n",
      "\n",
      "[[  1 -45 -51  42 -89]\n",
      " [-47  37 -97  48  26]\n",
      " [  6 -17 -23  29 -19]\n",
      " [-17 -63   6  65 -12]\n",
      " [ -1  26 -13  36  23]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Making 2 Random 5x5 Matrix\n",
    "\n",
    "mat1 = np.random.randint(1,100 , size=(5,5),dtype='int16')\n",
    "mat2 = np.random.randint(1,100 , size=(5,5),dtype='int16')\n",
    "\n",
    "# Showing Mat1 and Mat2\n",
    "\n",
    "print(f\"\\nMatrix 1\\n\")\n",
    "print(mat1)\n",
    "\n",
    "print(f\"\\nMatrix 2\\n\")\n",
    "print(mat2)\n",
    "\n",
    "# Subtracting the matrices\n",
    "\n",
    "mat3 = mat1-mat2\n",
    "\n",
    "print(f\"\\nResultant Matrix\\n\")\n",
    "print(mat3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 align = center><font color = '#46C7C7'>Multiplication</font></h2>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix 1\n",
      "\n",
      "[[83  1 51 21 48]\n",
      " [91 10 28 16 16]\n",
      " [23 44 61 41 35]\n",
      " [45 95 11 58 63]\n",
      " [48 20 25 91 73]]\n",
      "\n",
      "Matrix 2\n",
      "\n",
      "[[54  1 13 31 91]\n",
      " [ 4 84 95 64 68]\n",
      " [ 3 41 82 37 78]\n",
      " [68 61 56 92 15]\n",
      " [89 69 22 55 93]]\n",
      "\n",
      "Resultant Matrix\n",
      "\n",
      "[[10339  6851  7588  9096 16378]\n",
      " [ 7550  4159  5677  6849 12873]\n",
      " [ 7504 11136 12547 11483 13713]\n",
      " [12394 16361 15146 16683 18142]\n",
      " [15432 13341 11276 16080 15832]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Making 2 Random 5x5 Matrix\n",
    "\n",
    "mat1 = np.random.randint(1,100 , size=(5,5),dtype='int16')\n",
    "mat2 = np.random.randint(1,100 , size=(5,5),dtype='int16')\n",
    "\n",
    "# Showing Mat1 and Mat2\n",
    "\n",
    "print(f\"\\nMatrix 1\\n\")\n",
    "print(mat1)\n",
    "\n",
    "print(f\"\\nMatrix 2\\n\")\n",
    "print(mat2)\n",
    "\n",
    "# Multiplying the matrices\n",
    "\n",
    "mat3 = np.matmul(mat1,mat2)\n",
    "\n",
    "print(f\"\\nResultant Matrix\\n\")\n",
    "print(mat3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 align = center><font color =#CC338B >Transpose a matrix and find the determinant and inverse of a matrix.\n",
    "</font></h2>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align = center> Making a random 10x10 Matrix </h3>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix 1\n",
      "\n",
      "[[62 33 17 37 96 89 72 44 67 88]\n",
      " [66 67 24 43  8 65 64 43 48 10]\n",
      " [ 9 25 80 40 90  4 77 82 57 79]\n",
      " [56 81 97 83 20 56 35 49 71 73]\n",
      " [ 3 72  7 35 67 75 64  8 60 30]\n",
      " [55 69  6  9 19  3 51 81 95 99]\n",
      " [93  8 21 87 60  7  8 53 65 74]\n",
      " [46 87 21  3 81 88 72 55 20 32]\n",
      " [98 95 76 10 81 94 48 67 62 11]\n",
      " [ 3 63 25 78  9 29 63 14 39 89]]\n"
     ]
    }
   ],
   "source": [
    "mat = np.random.randint(1,100 , size=(10,10),dtype='int16')\n",
    "\n",
    "# Showing Matrix\n",
    "\n",
    "print(f\"\\nMatrix 1\\n\")\n",
    "print(mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2 align = center> <font color = '#38ACEC'> Transposing the matrix </font></h2>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### What is Transposing Matrix ?\n",
    "\n",
    "A transposed matrix is obtained by swapping the rows and columns of the original matrix. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transposed Matrix\n",
      "\n",
      "[[62 66  9 56  3 55 93 46 98  3]\n",
      " [33 67 25 81 72 69  8 87 95 63]\n",
      " [17 24 80 97  7  6 21 21 76 25]\n",
      " [37 43 40 83 35  9 87  3 10 78]\n",
      " [96  8 90 20 67 19 60 81 81  9]\n",
      " [89 65  4 56 75  3  7 88 94 29]\n",
      " [72 64 77 35 64 51  8 72 48 63]\n",
      " [44 43 82 49  8 81 53 55 67 14]\n",
      " [67 48 57 71 60 95 65 20 62 39]\n",
      " [88 10 79 73 30 99 74 32 11 89]]\n"
     ]
    }
   ],
   "source": [
    "transposedMatrix = np.transpose(mat)\n",
    "print(f\"\\nTransposed Matrix\\n\")\n",
    "print(transposedMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 align = center> <font color = '#00A36C'> Finding Determinant </font></h2>\n",
    "\n",
    "---\n",
    "\n",
    "#### What is Determinant?\n",
    "\n",
    "The determinant of a square matrix is a scalar value that can be computed from the elements of the matrix and has many important properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Determinant of Matrix 1: 6.74143640098782e+18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "determinant = np.linalg.det(mat)\n",
    "print(f\"\\nDeterminant of Matrix 1: {determinant}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 align = center> <font color = '#FF6700'> Matrix Inverse </font></h2>   \n",
    "\n",
    "---\n",
    "#### What is Matrix Inverse?\n",
    "\n",
    "The inverse of a square matrix is another square matrix that has the same dimension as the original matrix and satisfies the following property:\n",
    "\n",
    "mat * inverseMat = inverseMat * mat = I\n",
    "\n",
    "where I is the identity matrix of the same size as the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inverse of Matrix\n",
      "\n",
      "[[ 2.98485304e-03 -6.56494185e-04 -3.26160883e-03 -1.99330647e-02\n",
      "  -1.22528894e-02 -1.57869810e-03  2.14327502e-03 -1.41072563e-02\n",
      "   2.56115872e-02  2.23781897e-02]\n",
      " [-1.19405850e-02 -7.79766351e-03 -3.83419596e-03 -4.76850492e-03\n",
      "   3.49563618e-03  2.80926290e-03  2.73435328e-03  4.36730041e-03\n",
      "   9.22642310e-03  1.07098644e-02]\n",
      " [ 2.65777316e-03 -3.71184217e-03  3.85018763e-03 -1.60619049e-03\n",
      "  -6.57875527e-03 -3.60608842e-03 -6.06293860e-03 -1.12916517e-02\n",
      "   1.43786725e-02  9.24170551e-03]\n",
      " [-6.45078272e-03  6.45442335e-03  1.04465457e-03  8.31596222e-03\n",
      "   6.55112963e-03 -4.68088105e-03  8.76195383e-03  8.67276541e-03\n",
      "  -1.48383123e-02 -7.66614173e-03]\n",
      " [-3.56193703e-03 -8.97417388e-03  2.24073889e-03 -8.49383525e-03\n",
      "   5.00487829e-03 -2.78757918e-03  5.86718483e-03  7.89313117e-05\n",
      "   8.59989895e-03  4.95226316e-03]\n",
      " [ 9.95994500e-03  5.36383662e-03 -4.17337505e-03  2.33112687e-02\n",
      "   3.35204587e-03 -9.98794088e-04 -4.28248825e-03  1.40857995e-02\n",
      "  -2.41938847e-02 -2.43992022e-02]\n",
      " [ 3.66770069e-03  9.22006110e-03  6.38566394e-03 -2.28920935e-02\n",
      "  -7.67815262e-03 -3.04567485e-03 -5.77483967e-03 -1.61705996e-02\n",
      "   1.82824964e-02  2.27781275e-02]\n",
      " [-4.96976295e-03  1.09622754e-02  4.05115926e-03  2.79541858e-02\n",
      "   4.55156629e-03  4.56837070e-03  3.85069475e-03  2.96830573e-02\n",
      "  -3.96984874e-02 -3.84260936e-02]\n",
      " [ 2.08840920e-03  2.76566536e-03  8.54366632e-04  2.49917881e-03\n",
      "   1.18478280e-02  5.43943683e-03 -1.91392741e-03 -1.31245766e-02\n",
      "   1.44509893e-04 -8.93576737e-03]\n",
      " [ 7.64383847e-03 -9.37535993e-03 -3.57158096e-03  1.18559272e-03\n",
      "  -8.02587058e-03  2.84099994e-03 -2.86086717e-03  8.85868862e-04\n",
      "   1.82462208e-03  8.30904595e-03]]\n"
     ]
    }
   ],
   "source": [
    "inverseMatrix = np.linalg.inv(mat)\n",
    "print(f\"\\nInverse of Matrix\\n\")\n",
    "print(inverseMatrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1 align = center><font color =#D462FF > 2. Solving Linear Equations</font></h1>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<h2 align = center> <font color = '#FF0080'> Use NumPy to solve a system of linear equations. </font></h2>\n",
    "\n",
    "---\n",
    "\n",
    "#### What is Linear Equation?\n",
    "\n",
    "A linear equation is an equation that can be written in the form of ax + by = c, where a, b, and c are constants and x and y are variables.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.33333333 -0.66666667]\n"
     ]
    }
   ],
   "source": [
    "# Example Equation :\n",
    "# x – y = 12 ---(1) \n",
    "# 2x + y = 22 ---(2)\n",
    "\n",
    "# Converting the equation into matrix form Ax = b\n",
    "\n",
    "a = np.array([[1,-1],[2,1]])\n",
    "b = np.array([12,22])\n",
    "\n",
    "x = np.linalg.solve(a,b)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Picture Solution\n",
    "\n",
    "<img src=\"sol.png\" alt=\"Linear Equations\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Linear Equation Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.  ,  2.25])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equation\n",
    "#  2x + 4y = 5\n",
    "#  6x + 8y = 6\n",
    "\n",
    "a = np.array([[2,4],[6,8]])\n",
    "b= np.array([5,6])\n",
    "\n",
    "x = np.linalg.solve(a,b)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2 align = center> <font color = '#0A7A8A'> Implement matrix factorization methods (LU decomposition, QR decomposition). </font></h2>\n",
    "\n",
    "---\n",
    "#### What is Matrix Factorization?\n",
    "\n",
    "Matrix factorization is a method for breaking down a matrix into simpler matrices. There are two main types of matrix factorization:\n",
    "\n",
    "1. LU Decomposition: This method decomposes a square matrix into a lower triangular matrix (L) and an upper triangular matrix (U).\n",
    "\n",
    "2. QR Decomposition: This method decomposes a square matrix into a orthogonal matrix (Q) and a upper triangular matrix (R).\n",
    "\n",
    "#### What is lower triangular matrix ?\n",
    "\n",
    "A lower triangular matrix is a square matrix in which all elements above the main diagonal are zero.\n",
    "\n",
    "#### What is upper triangular matrix ?\n",
    "\n",
    "An upper triangular matrix is a square matrix in which all elements below the main diagonal are zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix 1\n",
      "\n",
      "[[99 27 25]\n",
      " [51 99  3]\n",
      " [47 65 35]]\n"
     ]
    }
   ],
   "source": [
    "### Making a random square matrix\n",
    "\n",
    "mat = np.random.randint(1,100 , size=(3,3),dtype='int16')\n",
    "\n",
    "# Showing Matrix\n",
    "\n",
    "print(f\"\\nMatrix 1\\n\")\n",
    "print(mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 align = center> <font color = '#38ACEC'> LU Decomposition </font></h2>\n",
    "\n",
    "---\n",
    "#### Applications:\n",
    "\n",
    "LU decomposition is used in various applications such as solving systems of linear equations, computing the inverse of a matrix, and solving linear least squares problems. It is particularly useful for solving systems of linear equations with a large number of variables.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lower Triangular Matrix (L):\n",
      "\n",
      "[[1.         0.         0.        ]\n",
      " [0.5151515  1.         0.        ]\n",
      " [0.47474748 0.6132478  1.        ]]\n",
      "\n",
      "Upper Triangular Matrix (U):\n",
      "\n",
      "[[99.       27.       25.      ]\n",
      " [ 0.       85.09091  -9.878788]\n",
      " [ 0.        0.       29.189459]]\n",
      "\n",
      "Final Resultant Matrix\n",
      "\n",
      "[[99. 27. 25.]\n",
      " [51. 99.  3.]\n",
      " [47. 65. 35.]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.linalg\n",
    "permutation,lower,upper = scipy.linalg.lu(mat)\n",
    "\n",
    "print(f\"\\nLower Triangular Matrix (L):\\n\")\n",
    "print(lower)\n",
    "print(f\"\\nUpper Triangular Matrix (U):\\n\")\n",
    "print(upper)\n",
    "\n",
    "# As we know we can get our orignal matrix back by multiplying permutation matrix with lower triangular matrix .\n",
    "# Then multiplying the resultant with upper triangular matrix. \n",
    "\n",
    "Q=np.dot(permutation,lower)\n",
    "\n",
    "print(\"\\nFinal Resultant Matrix\\n\")\n",
    "print(np.dot(Q,upper))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2 align = center> <font color = '#00A36C'> QR Decomposition </font></h2>\n",
    "\n",
    "---\n",
    "\n",
    "#### Usage:\n",
    "\n",
    "QR decomposition is used in various applications such as solving systems of linear equations, computing the singular value decomposition (SVD), and finding the nearest matrix to a given matrix. It is particularly useful for solving linear least squares problems and computing the eigenvalues and eigenvectors of a matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix 1\n",
      "\n",
      "[[ 37  68 599  73]\n",
      " [909 890 989 509]\n",
      " [211 257  33 987]\n",
      " [733 357 468 630]]\n",
      "\n",
      "Orthogonal Matrix (Q):\n",
      "\n",
      "[[-0.03116559 -0.12917817  0.91235484 -0.38723424]\n",
      " [-0.76566273 -0.54790214  0.03836995  0.33480081]\n",
      " [-0.17772809 -0.29674641 -0.40692038 -0.84544077]\n",
      " [-0.6174156   0.77139991  0.02349902 -0.15227594]]\n",
      "\n",
      "Upper Triangular Matrix (R):\n",
      "\n",
      "[[-1187.20680591  -949.65257476 -1070.72415157  -956.38686903]\n",
      " [    0.          -297.2910817   -268.03041702   -95.21895914]\n",
      " [    0.             0.           582.01760007  -300.69382133]\n",
      " [    0.             0.             0.          -788.23837281]]\n",
      "\n",
      "Final Resultant Matrix\n",
      "\n",
      "[[ 37.  68. 599.  73.]\n",
      " [909. 890. 989. 509.]\n",
      " [211. 257.  33. 987.]\n",
      " [733. 357. 468. 630.]]\n"
     ]
    }
   ],
   "source": [
    "mat = np.random.randint(1,1000 , size=(4,4), dtype='int16')\n",
    "\n",
    "# Showing Matrix\n",
    "\n",
    "print(f\"\\nMatrix 1\\n\")\n",
    "print(mat)\n",
    "\n",
    "# QR Decomposition\n",
    "\n",
    "Q,R = np.linalg.qr(mat)\n",
    "\n",
    "print(f\"\\nOrthogonal Matrix (Q):\\n\")\n",
    "print(Q)\n",
    "\n",
    "print(f\"\\nUpper Triangular Matrix (R):\\n\")\n",
    "print(R)\n",
    "\n",
    "# Multiplying Q and R to get original matrix\n",
    "\n",
    "print(\"\\nFinal Resultant Matrix\\n\")\n",
    "print(np.dot(Q,R))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align = center> <font color = 'gold'> Application </font></h2>\n",
    "\n",
    "#### What is singular matrix ? \n",
    "\n",
    "A singular matrix is a square matrix that does not have an inverse. In other words, its determinant is zero. This means that the system of linear equations Ax = b has either no solution, infinitely many solutions, or a unique solution depending on the values of the constants a1, a2,..., an.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solution: x = 19.99999999999999, y = -2.869792300935271e-15, z = -4.999999999999996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For example, we can use QR decomposition to solve a system of linear equations.\n",
    "\n",
    "# Equation\n",
    "\n",
    "#  2x + 9y + 6z = 10\n",
    "#  3x + 6y + 9z = 15\n",
    "#  4x + 8y + 12z = 20\n",
    "\n",
    "a = np.array([[2,9,6],[3,6,9],[4,8,12]])\n",
    "b= np.array([10,15,20])\n",
    "\n",
    "# sol = np.linalg.solve(a,b) This Can't be run because the matrix is singular. QR decomposition or other methods can be used to find a least-squares solution in such cases.\n",
    "\n",
    "# Perform QR decomposition\n",
    "Q, R = np.linalg.qr(a)\n",
    "\n",
    "# Solve for x, y, z\n",
    "QT_b = np.dot(Q.T, b)\n",
    "x = np.linalg.solve(R, QT_b)\n",
    "\n",
    "print(f\"\\nSolution: x = {x[0]}, y = {x[1]}, z = {x[2]}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1 align = center><font color =#AABB44 > 3. Eigenvalues and Eigenvectors</font></h1>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Eigenvalues ? \n",
    "\n",
    "Eigenvalues are scalar values associated with a square matrix. They are solutions to the characteristic equation det(A - λI) = 0, where A is the matrix and λ is the eigenvalue. Eigenvalues can be found using the numpy.linalg.eig() function.\n",
    "\n",
    "#### What is Eigenvectors ?\n",
    "\n",
    "Eigenvectors are non-zero vectors that, when multiplied by a square matrix, produce a scaled version of themselves. They are related to eigenvalues and are found using the numpy.linalg.eig() function.\n",
    "\n",
    "#### What is the relationship between Eigenvalues and Eigenvectors ?\n",
    "\n",
    "Eigenvalues and eigenvectors have a significant relationship in linear algebra. They are used to analyze the properties of linear transformations and solve systems of linear equations. For example, eigenvalues and eigenvectors can be used to determine the stability of a system of linear differential equations, to find the principal components of a dataset, and to perform PCA (Principal Component Analysis) for dimensionality reduction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2 align = center> <font color = 'Orchid'> Calculate the eigenvalues and eigenvectors of a given matrix.. </font></h2>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eigenvalues:\n",
      "\n",
      "[4. 2. 1.]\n",
      "\n",
      "Eigenvectors:\n",
      "\n",
      "\n",
      "Eigenvector 1:\n",
      "\n",
      "[-0.40824829 -0.81649658 -0.40824829]\n",
      "\n",
      "Eigenvector 2:\n",
      "\n",
      "[ 7.07106781e-01 -3.45742585e-16 -7.07106781e-01]\n",
      "\n",
      "Eigenvector 3:\n",
      "\n",
      "[ 0.57735027 -0.57735027  0.57735027]\n"
     ]
    }
   ],
   "source": [
    "mat = np.array([[2, 1, 0],\n",
    "                [1, 3, 1],\n",
    "                [0, 1, 2]])\n",
    "\n",
    "# Calculate eigenvalues and eigenvectors\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(mat)\n",
    "\n",
    "print(f\"\\nEigenvalues:\\n\")\n",
    "print(eigenvalues)\n",
    "\n",
    "print(f\"\\nEigenvectors:\\n\")\n",
    "\n",
    "for i in range(len(eigenvalues)):\n",
    "    print(f\"\\nEigenvector {i+1}:\\n\")\n",
    "    print(eigenvectors[:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2 align = center> <font color = 'Lime'> Verify the results by reconstructing the original matrix.\n",
    " </font></h2>\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reconstructed Matrix:\n",
      "\n",
      "[[2.00000000e+00 1.00000000e+00 3.34106299e-16]\n",
      " [1.00000000e+00 3.00000000e+00 1.00000000e+00]\n",
      " [2.27686080e-16 1.00000000e+00 2.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Formula for reconstructing the original matrix\n",
    "\n",
    "#A = P Λ P^-1.\n",
    "\n",
    "# Reconstruct the original matrix\n",
    "\n",
    "A = np.diag(eigenvalues)\n",
    "P = eigenvectors\n",
    "\n",
    "reconstructedMatrix = np.dot(np.dot(P,A),np.linalg.inv(P))\n",
    "\n",
    "\n",
    "print(f\"\\nReconstructed Matrix:\\n\")\n",
    "print(reconstructedMatrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1 align = center><font color =#BF4311 > 4. Vector Operations</font></h1>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a Vector ? \n",
    "\n",
    "A vector is a geometric object that has magnitude (length) and direction. In other words, a vector is a one-dimensional array of numbers. Vectors can be represented using arrow notation, where the arrow starts at the origin (0, 0, 0) and points in the specified direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2 align = center> <font color = 'purple'> Perform basic vector operations (addition, dot product, cross product). </font></h2>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Addition Result:\n",
      "\n",
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "# Making 2 vectors\n",
    "\n",
    "v1 = np.array([1, 2, 3])\n",
    "v2 = np.array([4, 5, 6])\n",
    "\n",
    "# Adding vectors\n",
    "\n",
    "result_addition = v1 + v2\n",
    "\n",
    "print(f\"\\nAddition Result:\\n\")\n",
    "print(result_addition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Product\n",
    "\n",
    "what is dot product ? \n",
    "\n",
    "dot product is a scalar value that represents the magnitude of one vector in the direction of another vector. It is calculated by multiplying the corresponding components of the two vectors and then summing the results.\n",
    "\n",
    "Example Code is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dot Product Result:\n",
      "\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# Dot product\n",
    "\n",
    "result_dot_product = np.dot(v1, v2)\n",
    "\n",
    "print(f\"\\nDot Product Result:\\n\")\n",
    "print(result_dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Product\n",
    "\n",
    "what is cross product? \n",
    "\n",
    "cross product is a vector that results from the multiplication of two vectors. It is calculated by finding the determinant of a 2x2 matrix formed by the two vectors.\n",
    "\n",
    "Example Code is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Product Result:\n",
      "\n",
      "[-3  6 -3]\n"
     ]
    }
   ],
   "source": [
    "#Cross product\n",
    "\n",
    "v1 = np.array([1, 2, 3])\n",
    "v2 = np.array([4, 5, 6])\n",
    "\n",
    "\n",
    "\n",
    "result_cross_product = np.cross(v1, v2)\n",
    "\n",
    "print(f\"\\nCross Product Result:\\n\")\n",
    "print(result_cross_product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2 align = center> <font color = 'MintCream'> Normalize a vector and compute vector norms. </font></h2>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is normalization of a vector?\n",
    "\n",
    "Normalization is the process of scaling a vector to have a magnitude of 1. It is done by dividing the vector by its length.\n",
    "\n",
    "#### What is vector norms ?\n",
    "\n",
    "Vector norms are measures of the size or length of a vector. There are several types of vector norms, such as:\n",
    "\n",
    "- Euclidean norm (L2 norm): sqrt(sum of squares of vector components)\n",
    "- Manhattan norm (L1 norm): sum of absolute values of vector components\n",
    "- Maximum norm (L Infinity norm): maximum absolute value of vector components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Vector Normalization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalized Vector:\n",
      "\n",
      "[0.07789417 0.21420895 0.97367706]\n"
     ]
    }
   ],
   "source": [
    "# Making a vector\n",
    "\n",
    "v = np.array([8, 22, 100])\n",
    "\n",
    "# Normalizing the vector\n",
    "\n",
    "normalized_v = v / np.linalg.norm(v)\n",
    "\n",
    "print(f\"\\nNormalized Vector:\\n\")\n",
    "print(normalized_v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "As we can see, the normalized vector has a magnitude of 1, and its elements are scaled such that the vector points in the same direction as the original vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Using Euclidean norm\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Euclidean Norm:\n",
      "\n",
      "102.70345661174214\n",
      "\n",
      "Normalized Vector Using Euclidean Norm:\n",
      "\n",
      "[0.07789417 0.21420895 0.97367706]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculating Euclidean norm\n",
    "\n",
    "euclideanNorm = np.linalg.norm(v)\n",
    "\n",
    "print(f\"\\nEuclidean Norm:\\n\")\n",
    "print(euclideanNorm)\n",
    "\n",
    "normalized_v = v / euclideanNorm\n",
    "\n",
    "print(f\"\\nNormalized Vector Using Euclidean Norm:\\n\")\n",
    "print(normalized_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Using Manhattan Norm\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manhattan Norm:\n",
      "\n",
      "130.0\n",
      "\n",
      "Normalized Vector Using Manhattan Norm:\n",
      "\n",
      "[0.06153846 0.16923077 0.76923077]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "manhattanNorm = np.linalg.norm(v, ord=1)\n",
    "\n",
    "print(f\"\\nManhattan Norm:\\n\")\n",
    "print(manhattanNorm)\n",
    "# Using Maximum Norm\n",
    "\n",
    "normalized_v = v / manhattanNorm\n",
    "\n",
    "print(f\"\\nNormalized Vector Using Manhattan Norm:\\n\")\n",
    "print(normalized_v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Norm:\n",
      "\n",
      "100.0\n",
      "\n",
      "Normalized Vector Using Infinity Norm:\n",
      "\n",
      "[0.08 0.22 1.  ]\n"
     ]
    }
   ],
   "source": [
    "# Using Infinity Norm\n",
    "\n",
    "infinityNorm = np.linalg.norm(v, ord=np.inf)\n",
    "\n",
    "print(f\"\\nMaximum Norm:\\n\")\n",
    "print(infinityNorm)\n",
    "\n",
    "normalized_v = v / infinityNorm\n",
    "\n",
    "print(f\"\\nNormalized Vector Using Infinity Norm:\\n\")\n",
    "print(normalized_v)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1 align = center><font color =#5865F2 > 5. Matrix Decomposition</font></h1>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<h2 align = center> <font color = 'blurple'> Understand and implement Principal Component Analysis (PCA) using SVD.\n",
    "  </font></h2>\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Principal Component Analysis ?\n",
    "\n",
    "Principal Component Analysis (PCA) is a statistical technique used to reduce the dimensionality of a dataset while retaining as much information as possible. It finds the principal components, or directions of maximum variance in the data, and projects the data onto these principal components to create a new, lower-dimensional representation.\n",
    "\n",
    "#### How does PCA work?\n",
    "\n",
    "1. Center the data: Subtract the mean of each feature from the corresponding data points to make the mean of each feature zero.\n",
    "\n",
    "2. Compute the covariance matrix: Calculate the covariance matrix of the centered data, which represents the correlation between the features.\n",
    "\n",
    "3. Compute the singular value decomposition (SVD): Perform the singular value decomposition (SVD) of the covariance matrix, using the numpy.linalg.svd() function. The SVD factors the covariance matrix into U, S, and V^T, where U and V^T are orthogonal matrices and S is a diagonal matrix with non-negative real numbers on the diagonal.\n",
    "\n",
    "4. Select the desired number of principal components: Select the desired number of principal components based on the desired explained variance ratio. The explained variance ratio is the proportion of the total variance that each principal component captures.\n",
    "\n",
    "5. Project the data onto the principal components: Multiply the centered data by the transpose of the selected principal components matrix (V^T) to obtain the new, lower-dimensional representation.\n",
    "\n",
    "\n",
    "\n",
    "#### What are benefits of Principal Component Analysis?\n",
    "\n",
    "- Reduces dimensionality: PCA helps reduce the dimensionality of a dataset by identifying the principal components that capture the most variance in the data.\n",
    "\n",
    "- Enhances data interpretability: Principal components are orthogonal, meaning they are uncorrelated, which makes them easier to interpret and visualize.\n",
    "\n",
    "- Improves computational efficiency: PCA can be computationally more efficient than other dimensionality reduction techniques, such as feature selection.\n",
    "\n",
    "- Preserves important information: PCA retains as much information as possible from the original dataset during the dimensionality reduction process, ensuring that the reduced representation retains the essential patterns and relationships.\n",
    "\n",
    "\n",
    "\n",
    "### What is covariance? \n",
    "\n",
    "Covariance is a measure of the linear relationship between two random variables. It quantifies the degree to which the two variables change together. This is very similar to correlation but there is no bounding of range(-1 to 1).\n",
    "\n",
    "### What is covariance matrix?\n",
    "\n",
    "Covariance matrix is a square matrix that represents the covariance between each pair of features in a dataset.\n",
    "\n",
    "\n",
    "\n",
    "#### What is Singular Value Decomposition (SVD) ?\n",
    "\n",
    "Singular Value Decomposition (SVD) is a matrix decomposition technique that factorizes a matrix into three matrices: U, Singular, and V^T. The U matrix contains the left singular vectors, the Singular matrix contains the singular values, and the V^T matrix contains the right singular vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
      "0         55        565        803        156        993         33   \n",
      "1        641         13        608        779        178        334   \n",
      "2        189        106        671        375        488        770   \n",
      "3        863        471        131        283        829        884   \n",
      "4        795        367        855        889        929        153   \n",
      "\n",
      "   Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_41  Feature_42  \\\n",
      "0        910        962        309         686  ...         509         493   \n",
      "1        961        437         78         787  ...         295         864   \n",
      "2        646        549        954         568  ...         825         874   \n",
      "3        850        805        606         513  ...         356         875   \n",
      "4        366        881        574         420  ...         870         575   \n",
      "\n",
      "   Feature_43  Feature_44  Feature_45  Feature_46  Feature_47  Feature_48  \\\n",
      "0          38         284         799         121         251         579   \n",
      "1         971          70         528         275          17         955   \n",
      "2         555         725         749         841         767         407   \n",
      "3         403         607         247         336         172         420   \n",
      "4         688         315         981         497         213         884   \n",
      "\n",
      "   Feature_49  Feature_50  \n",
      "0         981         775  \n",
      "1         692         775  \n",
      "2         732         455  \n",
      "3         301         922  \n",
      "4          63         122  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Generating random data\n",
    "n_samples = 100\n",
    "n_features = 50\n",
    "randomData = np.random.randint(1,1000,size=(n_samples, n_features),)\n",
    "\n",
    "data = pd.DataFrame(randomData, columns=[f'Feature_{i+1}' for i in range(n_features)])\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Random Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.random.randint(0, 2, size=n_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "### Training Linear Regression Model\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test data\n",
    "\n",
    "model.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "normalizedData = scaler.fit_transform(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covalence can be found using transpose of normalizedData\n",
    "covarianceMatrix = np.cov(normalizedData.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.056521   0.10432247 0.15071886 0.19368208 0.23579358 0.27594389\n",
      " 0.31501684 0.35177655 0.38780377 0.42242575 0.45627618 0.4887619\n",
      " 0.52042263 0.54866054 0.5764473  0.6029436  0.62816531 0.65206618\n",
      " 0.67522888 0.69706514 0.71818377 0.738138   0.75738341 0.77546554\n",
      " 0.79252319 0.80769864 0.82236769 0.83648994 0.85013001 0.86338759\n",
      " 0.87616591 0.88798553 0.89902291 0.90931199 0.91897972 0.92850288\n",
      " 0.93701379 0.94536179 0.9531522  0.9603325  0.9665607  0.97210224\n",
      " 0.97723433 0.98166925 0.98597041 0.98934857 0.99237785 0.99528899\n",
      " 0.99774675 1.        ]\n",
      "(100, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from numpy.linalg import svd\n",
    "\n",
    "U, S, VT = svd(covarianceMatrix)\n",
    "\n",
    "\n",
    "eigenValues = S**2\n",
    "eigenVectors = VT.T\n",
    "\n",
    "## Here we are finding ratio variance that a singular value explains\n",
    "explainedVariance = S / np.sum(S)\n",
    "\n",
    "## Here we are finding cumulative sum of explained variance.\n",
    "cumulativeVariance = np.cumsum(explainedVariance )\n",
    "\n",
    "\n",
    "\n",
    "k = np.argmax(cumulativeVariance >= 0.95) + 1\n",
    "\n",
    "\n",
    "\n",
    "principalComponents = VT.T[:,:k]\n",
    "\n",
    "transformedData = np.dot(normalizedData, principalComponents)\n",
    "\n",
    "transformedData.shape\n",
    "\n",
    "transformed_df = pd.DataFrame(transformedData, columns=[f'PC{i+1}' for i in range(k)])\n",
    "\n",
    "print(transformed_df.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_df, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test data\n",
    "\n",
    "model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "The Principal Component Analysis (PCA) has been successfully applied to the dataset. The covariance matrix has been computed, and Singular Value Decomposition (SVD) has been performed to obtain the principal components. The transformed data has been obtained by projecting the original data onto the principal components.\n",
    "\n",
    "The Model with all the features and The model with 40 features giving the same score. \n",
    "\n",
    "The final transformed dataset has 100 samples and 40 principal components. The model has been trained using the transformed data and evaluated on the test set. The accuracy of the model is approximately 50% , indicating that the PCA dimensionality reduction technique has successfully preserved the essential patterns and relationships in the original dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<h1 align = center><font color = #64E986 >Calculus Tasks</font></h1>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<h2 align = center> <font color = '#FE632A'> \n",
    "\n",
    " 1.Numerical Differentiation\n",
    "\n",
    "  </font></h2>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2 align = center> <font color = 'pink'> \n",
    "\n",
    "Use NumPy to compute the numerical derivative of a given function.\n",
    "  </font></h2>\n",
    "\n",
    "  \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Numerical derivative of function?\n",
    "\n",
    "Numerical derivative is a technique used to approximate the derivative of a function by computing the difference between the function values at two points, divided by the difference between the two points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical derivative using central difference method at x = [1 2 3 4]:\n",
      "[ 5.         16.         33.00000001 56.00000001]\n",
      "\n",
      "Analytical derivative at x = [1 2 3 4]:\n",
      "[ 5 16 33 56]\n"
     ]
    }
   ],
   "source": [
    "# Given function\n",
    "\n",
    "# f(x) = x^3 + x^2 + 5\n",
    "\n",
    "def f(x):\n",
    "    return x**3 + x**2 + 5\n",
    "\n",
    "\n",
    "\n",
    "# Numerical Derivative \n",
    "\n",
    "def numericalDerivative(f, x, h=1e-6):\n",
    "    return (f(x + h) - f(x - h)) / (2 * h)\n",
    "\n",
    "# Compute numerical derivative using forward difference method\n",
    "\n",
    "x = np.arange(1,5)\n",
    "\n",
    "\n",
    "# Compute numerical derivative using central difference method\n",
    "\n",
    "print(f\"\\nNumerical derivative using central difference method at x = {x}:\")\n",
    "print(numericalDerivative(f, x))\n",
    "\n",
    "\n",
    "\n",
    "# Now Checking the derivative using analytical method\n",
    "def derivative(x): # Returning the derivative of function\n",
    "    return 3 * x**2 + 2 * x \n",
    "\n",
    "print(f\"\\nAnalytical derivative at x = {x}:\")\n",
    "print(derivative(x))\n",
    "\n",
    "\n",
    "# As we can see analytical derivatives and numerical derivatives are approximately same\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align = center> <font color = 'applegreen'> \n",
    "\n",
    "Implement forward, backward, and central difference methods for differentiation\n",
    "\n",
    "  </font></h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Forward Method\n",
    "\n",
    "---\n",
    "\n",
    "Formula:\n",
    "\n",
    "f'(x) = (f(x + h) - f(x)) / h\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forward difference method at x = [1 2 3 4]:\n",
      "[ 6.000003   12.000003   18.000003   24.00000299]\n",
      "\n",
      "Analytical derivative at x = [1 2 3 4]:\n",
      "[ 6 12 18 24]\n"
     ]
    }
   ],
   "source": [
    "# Given Function\n",
    "\n",
    "# f(x) = 3x^2 + 2\n",
    "\n",
    "def f(x):\n",
    "    return 3 * x**2 + 2\n",
    "\n",
    "# Forward difference method\n",
    "\n",
    "def forwardDifference(x, h=1e-6):\n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "# Compute forward difference method\n",
    "\n",
    "x = np.arange(1,5)\n",
    "\n",
    "print(f\"\\nForward difference method at x = {x}:\")\n",
    "print(forwardDifference(x))\n",
    "\n",
    "# Now Checking the derivative using analytical method\n",
    "\n",
    "def derivative(x): # Returning the derivative of function\n",
    "    return 6 * x\n",
    "\n",
    "print(f\"\\nAnalytical derivative at x = {x}:\")\n",
    "print(derivative(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Backword Method\n",
    "\n",
    "---\n",
    "\n",
    "Formula:\n",
    "\n",
    "f'(x) = (f(x) - f(x - h)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backward difference method at x = [1 2 3 4]:\n",
      "[ 5.999997 11.999997 17.999997 23.999997]\n"
     ]
    }
   ],
   "source": [
    "# Given Function\n",
    "\n",
    "# f(x) = 3x^2 + 2\n",
    "\n",
    "def f(x):\n",
    "    return 3 * x**2 + 2\n",
    "\n",
    "# Backward difference method\n",
    "\n",
    "def backwardDifference(x,h = 1e-6):\n",
    "    return ((f(x) - f(x-h))/h)\n",
    "\n",
    "# Compute backward difference method\n",
    "\n",
    "x = np.arange(1,5)\n",
    "\n",
    "print(f\"\\nBackward difference method at x = {x}:\")\n",
    "print(backwardDifference(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Central difference method\n",
    "\n",
    "---\n",
    "\n",
    "Formula:\n",
    "\n",
    "f'(x) = (f(x + h) - f(x - h)) / (2h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Central difference method at x = [1 2 3 4]:\n",
      "[ 6. 12. 18. 24.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def f(x):\n",
    "    return 3 * x**2 + 2\n",
    "\n",
    "# Central difference method\n",
    "\n",
    "def centralDifference(x,h = 1e-6):\n",
    "    return ((f(x+h) - f(x-h))/(2*h))\n",
    "\n",
    "# Compute central difference method\n",
    "\n",
    "x = np.arange(1,5)\n",
    "\n",
    "print(f\"\\nCentral difference method at x = {x}:\")\n",
    "print(centralDifference(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<h2 align = center> <font color = '#7F38EC'> \n",
    "\n",
    " 2.Numerical Integration\n",
    "\n",
    "\n",
    "  </font></h2>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Numerical Integration\n",
    "\n",
    "Numerical integration is a technique used to approximate the definite integral of a function by approximating the area under the curve of the function over a given interval. There are two main types of numerical integration methods: trapezoidal rule and Simpson's rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2 align = center> <font color = 'Silver'> \n",
    "\n",
    "Use NumPy to compute the numerical integral of a given function.\n",
    "\n",
    "  </font></h2>\n",
    "\n",
    "\n",
    "  ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical integral of f(x) from 0 to 4 is: 53.333376171180035\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the function\n",
    "# f(x) = x^2 + 3x + 2\n",
    "def f(x):\n",
    "    return x**2 + 3*x + 2\n",
    "\n",
    "# Intervals [a, b]\n",
    "a, b = 0, 4\n",
    "\n",
    "# Number of points\n",
    "num_points = 500\n",
    "\n",
    "# Create an array of x values from a to b\n",
    "x = np.linspace(a, b, num_points)\n",
    "\n",
    "\n",
    "# Compute the numerical integral using the trapezoidal rule\n",
    "integral = np.trapezoid(f(x), x)\n",
    "\n",
    "print(\"Numerical integral of f(x) from {} to {} is: {}\".format(a, b, integral))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 align = center> <font color = 'Cheese'> \n",
    "Implement the trapezoidal rule and Simpson's rule for integration.\n",
    "  </font></h2>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Using Trapezoidal Rule\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Trapezoidal Rule:\n",
    "\n",
    "Integral[a, b] = (h/2) * [f(x0) + 2*f(x1) + 2*f(x2) +... + 2*f(xn-1) + f(xn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical integral of f(x) from 0 to 4 is: 53.333376171180035\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the function\n",
    "# f(x) = x^2 + 3x + 2\n",
    "def f(x):\n",
    "    return x**2 + 3*x + 2\n",
    "\n",
    "# Intervals [a, b]\n",
    "a, b = 0, 4\n",
    "\n",
    "# Number of points\n",
    "num_points = 500\n",
    "\n",
    "# Create an array of x values from a to b\n",
    "x = np.linspace(a, b, num_points)\n",
    "\n",
    "\n",
    "# Compute the numerical integral using the trapezoidal rule\n",
    "integral = np.trapezoid(f(x), x)\n",
    "\n",
    "print(f\"Numerical integral of f(x) from {a} to {b} is: {integral}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "### Using Simson's Rule For Integration\n",
    "\n",
    "---\n",
    "\n",
    "Simpson's 1/3 Rule:\n",
    "\n",
    "Integral[a, b] = (h/3) * [f(x0) + 4*f(x1) + 2*f(x2) +... + 4*f(xn-2) + f(xn-1)]\n",
    "\n",
    "\n",
    "where:\n",
    "\n",
    "h = (b - a) / (num_points - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical integral of f(x) from 0 to 4 is: 53.093441048412075\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the function\n",
    "def f(x):\n",
    "    return x**2 + 3*x + 2\n",
    "\n",
    "# Intervals [a, b]\n",
    "a, b = 0, 4\n",
    "\n",
    "# Number of points\n",
    "num_points = 500\n",
    "\n",
    "# Create an array of x values from a to b\n",
    "x = np.linspace(a, b, num_points)\n",
    "\n",
    "\n",
    "# Compute the numerical integral using Simpson's rule\n",
    "h = (b - a) / (num_points - 1)\n",
    "integral = f(x[0]) + f(x[-1]) + 4 * np.sum(f(x[1:-1:2])) + 2 * np.sum(f(x[2:-2:2]))\n",
    "integral *= h / 3\n",
    "\n",
    "print(f\"Numerical integral of f(x) from {a} to {b} is: {integral}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<h2 align = center> <font color = '#6F2DA8'>3. Partial Derivatives</font></h2>\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2 align = center> <font color = 'crimson'> \n",
    "Calculate partial derivatives of multivariable functions using NumPy.\n",
    "  </font></h2>\n",
    "\n",
    "\n",
    "  ---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is partial derivatives ?\n",
    "\n",
    "Partial derivatives are used to find the rate of change of a function with respect to one of its variables while keeping the others constant. They are represented as partial derivatives with respect to each variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formula\n",
    "\n",
    "<img src=\"formula.png\" alt=\"Partial Derivative\">\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial derivative of f(2, 5) with respect to x: 19.00000100363286\n",
      "Partial derivative of f(2, 5) with respect to y: 26.0000020091411\n"
     ]
    }
   ],
   "source": [
    "# Define a function\n",
    "\n",
    "def f(x, y):\n",
    "    return x**2 + 3*x*y + 2*y**2\n",
    "\n",
    "# Compute partial derivatives\n",
    "x = 2\n",
    "y= 5\n",
    "\n",
    "dx = 1e-6\n",
    "dy = 1e-6\n",
    "\n",
    "\n",
    "# Compute partial derivative with respect to x\n",
    "\n",
    "partial_x = (f(x + dx, y)-f(x,y))/dx\n",
    "\n",
    "# Compute partial derivative with respect to y\n",
    "\n",
    "partial_y = (f(x,y+dy)-f(x,y))/dy\n",
    "\n",
    "# Print the partial derivatives\n",
    "\n",
    "print(f\"Partial derivative of f({x}, {y}) with respect to x: {partial_x}\")\n",
    "print(f\"Partial derivative of f({x}, {y}) with respect to y: {partial_y}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<h2 align = center> <font color = 'neonGreen'> \n",
    "Verify results by comparing with analytical solutions.\n",
    "\n",
    "  </font></h2>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical partial derivative of f(2, 5) with respect to x: 19\n",
      "Analytical partial derivative of f(2, 5) with respect to y: 26\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### Analytical solutions\n",
    "\n",
    "# Analytical solutions to the partial derivatives of the given function f(x, y) are:\n",
    "\n",
    "# Function: x**2 + 3*x*y + 2*y**2\n",
    "\n",
    "# Compute the analytical solutions\n",
    "\n",
    "analytical_partial_x = 2*x + 3*y # This equation is accuired by taking derivative of given function by x \n",
    "analytical_partial_y = 3*x + 4*y # This equation is accuired by taking derivative of given function by y\n",
    "\n",
    "# Print the analytical solutions\n",
    "\n",
    "print(f\"Analytical partial derivative of f({x}, {y}) with respect to x: {analytical_partial_x}\")\n",
    "print(f\"Analytical partial derivative of f({x}, {y}) with respect to y: {analytical_partial_y}\")\n",
    "\n",
    "\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "Partial derivative of f(2, 5) with respect to x: 19.00000100363286\n",
    "Partial derivative of f(2, 5) with respect to y: 26.0000020091411\n",
    "\n",
    "Analytical partial derivative of f(2, 5) with respect to x: 19   \n",
    "Analytical partial derivative of f(2, 5) with respect to y: 26\n",
    "\n",
    "\n",
    "As we can see , the partial derivatives solution find by numeric methods and analytical methods are approximately same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "<h2 align = center> <font color = '\t#228B22'> 4. Optimization</font></h2>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is optimization?\n",
    "\n",
    "Optimization is the process of finding the best possible outcome or values for a set of variables, given a specific objective function and constraints. It can be used to find the best solutions to problems like finding the best parameters for a machine learning model, finding the optimal location for a production facility, or finding the best allocation of resources to meet demand.\n",
    "\n",
    "Optimization problems can be classified into two main types: unconstrained and constrained optimization problems. Unconstrained optimization problems have no constraints on the variables, while constrained optimization problems have some restrictions or constraints on the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "<h2 align = center> <font color = '#FFFF00'> Use NumPy to solve optimization problems with constraints.</font></h2>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are optimization problems?\n",
    "\n",
    "Optimization problems involve finding the best possible solution to a specific objective function subject to certain constraints. Examples of optimization problems include finding the minimum or maximum value of a function, finding the best combination of variables to achieve a desired outcome, or finding the best allocation of resources to meet a given deadline.\n",
    "\n",
    "Optimization problems can be solved using various algorithms, such as gradient descent, gradient ascent, and simulated annealing, to find the optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Maximization Problem\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "A company produces three products: Product X, Product Y, and Product Z. The company aims to maximize its profit from these products. The profit margins per unit sold are as follows:\n",
    "\n",
    "- Product X yields a profit of $3 per unit.\n",
    "- Product Y yields a profit of $5 per unit.\n",
    "- Product Z yields a profit of $4 per unit.\n",
    "\n",
    "\n",
    "However, the company faces constraints in production and resources:\n",
    "\n",
    "1. Each unit of Product X requires 2 units of a specific raw material and 3 units of labor, and the total availability of these resources is limited to 8 units.\n",
    "\n",
    "2. Each unit of Product Y requires 2 units of labor and 5 units of another raw material, with a total of 10 units available for these resources.\n",
    "\n",
    "3. Each unit of Product Z requires 3 units of Product X, 2 units of Product Y, and 4 units of another raw material, with a total of 15 units available for these resources.\n",
    "\n",
    "4. The company cannot produce a negative number of any product.\n",
    "\n",
    "\n",
    "The objective is to determine how many units of each product the company should produce to maximize its total profit while adhering to these constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "\n",
    "Maximize: Z = 3x + 5y + 4z\n",
    "\n",
    "\n",
    "### Equation\n",
    "\n",
    "\n",
    "Constraints:\n",
    "\n",
    "2x + 3y <= 8   \n",
    "2y + 5z <= 10  \n",
    "3x + 2y + 4z <= 15   \n",
    "x >= 0 and y >= 0 and z >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        message: Optimization terminated successfully. (HiGHS Status 7: Optimal)\n",
      "        success: True\n",
      "         status: 0\n",
      "            fun: -18.65853658536585\n",
      "              x: [ 2.171e+00  1.220e+00  1.512e+00]\n",
      "            nit: 3\n",
      "          lower:  residual: [ 2.171e+00  1.220e+00  1.512e+00]\n",
      "                 marginals: [ 0.000e+00  0.000e+00  0.000e+00]\n",
      "          upper:  residual: [       inf        inf        inf]\n",
      "                 marginals: [ 0.000e+00  0.000e+00  0.000e+00]\n",
      "          eqlin:  residual: []\n",
      "                 marginals: []\n",
      "        ineqlin:  residual: [ 0.000e+00  0.000e+00  0.000e+00]\n",
      "                 marginals: [-1.098e+00 -5.854e-01 -2.683e-01]\n",
      " mip_node_count: 0\n",
      " mip_dual_bound: 0.0\n",
      "        mip_gap: 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linprog\n",
    "\n",
    "# Cost Matrix\n",
    "cost = [-3, -5, -4]\n",
    "\n",
    "# Left-hand side of equations\n",
    "leftHandSide = [\n",
    "    [2, 3, 0],  \n",
    "    [0, 2, 5],  \n",
    "    [3, 2, 4]   \n",
    "]\n",
    "\n",
    "# Right-hand side of equations\n",
    "rightHandSide = [8, 10, 15]\n",
    "\n",
    "# Solving Maximization Problem\n",
    "optimumSolution = linprog(c=cost, A_ub=leftHandSide, b_ub=rightHandSide, method=\"highs\")\n",
    "\n",
    "# Printing Result\n",
    "print(optimumSolution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The solution provided by the solver suggests that producing approximately \n",
    "2.171\n",
    "2.171 units of Product X, \n",
    "1.22\n",
    "1.22 units of Product Y, and \n",
    "1.512\n",
    "1.512 units of Product Z will maximize the profit, Which will be 18.65 USD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Minimization Problem\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statment:\n",
    "\n",
    "A manufacturing company is producing two products, Product A and Product B. The company aims to minimize the total production cost. The cost of producing one unit of Product A is $1, and the cost of producing one unit of Product B is also $1.\n",
    "\n",
    "However, the production process is subject to the following constraints:\n",
    "\n",
    "Resource Constraint 1:\n",
    "\n",
    "The production of Product A and Product B requires certain raw materials. Specifically, 2 units of raw material are needed for each unit of Product A, and 4 units of raw material are needed for each unit of Product B. The total amount of this raw material available must be at least 4 units.\n",
    "Resource Constraint 2:\n",
    "\n",
    "There is another resource constraint where each unit of Product A requires 1 unit of a secondary material, and each unit of Product B requires 7 units of this secondary material. The total amount of this secondary material available must be at least 7 units.\n",
    "Non-negativity Constraint:\n",
    "\n",
    "The company cannot produce a negative number of units of either product, meaning the quantities of both products must be non-negative.\n",
    "The company needs to determine the number of units of Product A (x1) and Product B (x2) to produce in order to minimize the total production cost while satisfying these constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "Minimize: Z = x1 + x2\n",
    "\n",
    "### Equation\n",
    "\n",
    "Constraints:\n",
    "\n",
    "2x1 + 4x2 >= 4  --> (1)   \n",
    "x1 + 7x2 >= 7  --> (2)     \n",
    "x1,x2 >= 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note :\n",
    "\n",
    "Since there is greater than sign in both equations,this is easily remedied by converting the “greater than” inequality constraint to a “less than” inequality constraint by multiplying both sides by -1 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the both equations will change into below : \n",
    "\n",
    "-2x1 -4x2 <= -4 -->(1)   \n",
    "-x1 -7x2 <= -7 -->(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        message: Optimization terminated successfully. (HiGHS Status 7: Optimal)\n",
      "        success: True\n",
      "         status: 0\n",
      "            fun: 1.0\n",
      "              x: [ 0.000e+00  1.000e+00]\n",
      "            nit: 0\n",
      "          lower:  residual: [ 0.000e+00  1.000e+00]\n",
      "                 marginals: [ 8.571e-01  0.000e+00]\n",
      "          upper:  residual: [       inf        inf]\n",
      "                 marginals: [ 0.000e+00  0.000e+00]\n",
      "          eqlin:  residual: []\n",
      "                 marginals: []\n",
      "        ineqlin:  residual: [ 0.000e+00  0.000e+00]\n",
      "                 marginals: [-0.000e+00 -1.429e-01]\n",
      " mip_node_count: 0\n",
      " mip_dual_bound: 0.0\n",
      "        mip_gap: 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linprog\n",
    "\n",
    "# Cost Matrix\n",
    "costMatrix = [1, 1]\n",
    "\n",
    "# Left-hand side of equations\n",
    "leftHandSide = [\n",
    "    [-2, -4], \n",
    "    [-1,-7 ]    \n",
    "]\n",
    "\n",
    "# Right-hand side of equations\n",
    "rightHandSide = [-4, -7]\n",
    "\n",
    "# Solving minimization problem\n",
    "optimumSolution = linprog(c=costMatrix, A_ub=leftHandSide, b_ub=rightHandSide,  method=\"highs\")\n",
    "\n",
    "# Printing Results\n",
    "print(optimumSolution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The solution shows the minimum production cost of $1 can be achieved by Making 0 units of Product A and 1 unit of Product B while satisfying all constraints. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
